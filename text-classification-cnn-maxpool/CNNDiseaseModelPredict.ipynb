{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "\n",
    "from dataOwn import *\n",
    "import pickle\n",
    "from CNNDiseaseModel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    bool(type(unicode))\n",
    "except NameError:\n",
    "    unicode = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CnnModel:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.config = TCNNConfig()\n",
    "        self.vocabulary_word2index, self.vocabulary_index2word  = create_voabulary(self.config.word2vec_model_path)\n",
    "        self.config.vocab_size = len(self.vocabulary_word2index)+1\n",
    "        #这里通过实际的word2vec模型统计词典中词的数量，赋值到config中，然后加载RNN模型\n",
    "        self.model = CNNDisease(self.config)\n",
    "        print(self.config.vocab_size)\n",
    "    \n",
    "        save_dir = 'checkpoints/textrnn'\n",
    "        save_path = os.path.join(save_dir, 'best_validation')  # 最佳验证结果保存路径\n",
    "\n",
    "    \n",
    "        self.session = tf.Session()\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess=self.session, save_path=save_path)  # 读取保存的模型\n",
    "\n",
    "    def predict(self, message):\n",
    "        # 支持不论在python2还是python3下训练的模型都可以在2或者3的环境下运行\n",
    "        #content = unicode(message)\n",
    "        x_temp = list([message.strip().split(\" \") ])\n",
    "        x = [[a.strip() for a in b]  for b in x_temp]\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x[i])):\n",
    "                x[i][j] = self.vocabulary_word2index.get(x[i][j],0)\n",
    "        data = np.array(x).tolist()\n",
    "        \n",
    "        #data = [self.vocabulary_word2index[x] for x in content if x in self.vocabulary_word2index]\n",
    "\n",
    "        feed_dict = {\n",
    "            self.model.input_x: pad_sequences(data, self.config.sequence_length),\n",
    "            self.model.dropout_keep_prob: 1.0\n",
    "        }\n",
    "\n",
    "        y_pred_cls = self.session.run(self.model.y_pred_cls, feed_dict=feed_dict)\n",
    "        return y_pred_cls[0]\n",
    "    def feed_data(self,x_batch, y_batch, keep_prob):\n",
    "        feed_dict = {\n",
    "            self.model.input_x: x_batch,\n",
    "            self.model.input_y: y_batch,\n",
    "            self.model.dropout_keep_prob: keep_prob\n",
    "        }\n",
    "        return feed_dict\n",
    "    def evaluate(self, x, y):\n",
    "        \"\"\"评估在某一数据上的准确率和损失\"\"\"\n",
    "        #batch_eval = batch_iter(x_, y_, config.batch_size)\n",
    "        batch_size = self.config.batch_size\n",
    "        total_loss = 0.0\n",
    "        total_acc = 0.0\n",
    "        eval_out = []\n",
    "        data_len = len(x)\n",
    "        num_batch = int((data_len - 1) / batch_size) + 1\n",
    "\n",
    "        indices = np.random.permutation(np.arange(data_len))\n",
    "        print(\"data_len=\", data_len, \" num_batch=\", num_batch)\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        x_shuffle = x[indices]\n",
    "        y_shuffle = y[indices]\n",
    "\n",
    "        for i in range(num_batch):\n",
    "            start_id = i * batch_size\n",
    "            end_id = min((i + 1) * batch_size, data_len)\n",
    "            x_batch, y_batch =  x_shuffle[start_id:end_id], y_shuffle[start_id:end_id]\n",
    "\n",
    "            batch_len = len(x_batch)\n",
    "            feed_dict = self.feed_data(x_batch, y_batch, 1.0)\n",
    "            loss, acc, y_pred_cls = self.session.run([self.model.loss, self.model.acc, self.model.y_pred_cls], feed_dict=feed_dict)\n",
    "            total_loss += loss * batch_len\n",
    "            total_acc += acc * batch_len\n",
    "            eval_out = np.concatenate([eval_out, y_pred_cls])\n",
    "\n",
    "        #这里为了获取shuffle之后的y，直接把得到批的过程拿过来了\n",
    "        return total_loss / data_len, total_acc / data_len, eval_out, y_shuffle\n",
    "    def test(self, x_val, y_val):\n",
    "\n",
    "        start_time = time.time()\n",
    "        print('Testing...')\n",
    "        total_loss, total_acc, eval_out, y_real = self.evaluate( x_val, y_val)\n",
    "        print(\"total_loss=\", total_loss, \" total_acc=\", total_acc)\n",
    "        print(metrics.classification_report(y_real,eval_out))\n",
    "\n",
    "        cm = metrics.confusion_matrix(y_real, eval_out)\n",
    "        print(\"cm====\\n\", cm)  \n",
    "    def predictBatch(self, test_data_path, test_label_path):\n",
    "        x_val, y_val = loadTrainOrTest_data_oneLabel(test_data_path, test_label_path, self.vocabulary_word2index)\n",
    "        x_val = pad_sequences(x_val, self.config.sequence_length)  # padding to max length   \\\n",
    "        self.test(x_val, y_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232015\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/textrnn/best_validation\n"
     ]
    }
   ],
   "source": [
    "cnn_model = CnnModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicPath = \"../datasets/firstCode2Index2TypeNew.txt\"\n",
    "typeDict = dict()\n",
    "for item in open(dicPath,\"r\").readlines():\n",
    "    itemArr = item.split(\" \")\n",
    "    typeDict[int(itemArr[1])] = itemArr[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 肿瘤\n",
      "\n",
      "7 肿瘤\n",
      "\n",
      "8 泌尿生殖系统疾病\n",
      "\n",
      "7 肿瘤\n",
      "\n",
      "8 泌尿生殖系统疾病\n",
      "\n",
      "7 肿瘤\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_demo = ['胃窦 凹陷性浮肿 粘膜隆起 慢性浅表性胃炎 HP 反跳痛 无压痛 电子胃镜 胃底 超声内镜检查 脾未触及 十二指肠球炎 病理性杂音 黄斑瘤 肺呼吸音 湿性啰音 巩膜无黄染 查体 入院 心率  胆汁 神志 下肢 糜烂 中年 腹部 平坦 辅助 女性 患者 检查 精神 建议',\n",
    "             '腹部 疼痛 阴性 患者 反酸 血管杂音 震水音 移动性浊音 里急后重 蠕动波 胃肠型 未触及 腹部叩诊音 反跳痛 右下腹压痛 右下腹部 肝脾肋下未触及 无明显诱因 腹壁静脉曲张 转移性右 下腹痛 鼓音 周围部 肠鸣音 上腹 阵发性 入院 腰痛 腹胀 胸闷 心悸 心慌 大便 放射 腹泻 未见 头痛 恶心 持续性 呕吐 发热 平坦 加重 转移 固定 紧张',\n",
    "            '未触及 转移性右下腹痛 血常规 腹部包块 腹部B超 肠型 移动性浊音 肋下 入院查体 反跳痛 右下腹压痛 肠鸣音 心肺听诊无异常 腹肌 囊肿 入院 神志 身体健康 未见 腹部 平坦 辅助 患者 检查 小时 精神',\n",
    "            '叩痛 肋下 反跳痛 肝脾 深压痛 右下腹痛 未触及 胃肠型 检查日期 蠕动波 肾区 检查单位 移动性浊音 肠鸣音 右下腹 查体 腹肌 入院 未及 未见 腹部 平坦'\n",
    "            ,'入院查体 轻度黄染 肌张力 双肺呼吸音清 肠鸣音 湿性啰音 小时 心音 入院 患儿 外貌 主因 肤色 新生儿 腹泻 哭声 发热 四肢 腹部 增强'\n",
    "            ,'急诊 黄染 无畸形 瓣膜听诊区 腹平软 干湿罗音 心肌酶 血钾 握持反射 指(趾)端 足月新生儿 觅食反射 前囟 肺呼吸音 吸吮反射 皮肤干燥 肝脾肋下未触及 拥抱反射 肌张力'\n",
    "            ]\n",
    "#输入文本\n",
    "'''\n",
    "test_data_path = \"../cnnDatasets/testAdmin.feature\"\n",
    "test_label_path = \"../cnnDatasets/testAdmin.label\"\n",
    "x_val, y_val = loadTrainOrTest_data_oneLabel_Source(test_data_path, test_label_path, cnn_model.vocabulary_word2index)\n",
    "count = 0\n",
    "for index in range(0,1500):\n",
    "    item = x_val[index]\n",
    "    if(y_val[index] == cnn_model.predict(item)):\n",
    "        count +=1\n",
    "    print(y_val[index],cnn_model.predict(item), typeDict[cnn_model.predict(item)])\n",
    "print(\"count=\", count)\n",
    "'''\n",
    "for i in test_demo:\n",
    "    print(cnn_model.predict(i), typeDict[cnn_model.predict(i)])\n",
    "#输入测试文件地址\n",
    "test_data_path = \"../cnnDatasets/testAdmin.feature\"\n",
    "test_label_path = \"../cnnDatasets/testAdmin.label\"\n",
    "#cnn_model.predictBatch(test_data_path, test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
