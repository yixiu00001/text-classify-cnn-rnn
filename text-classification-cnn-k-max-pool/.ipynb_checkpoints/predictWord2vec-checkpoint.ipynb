{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "\n",
    "from modelOneConv import *\n",
    "from dataOwn import *\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CnnKMaxPoolModel:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.config = TCNN_K_Config()\n",
    "        self.vocabulary_word2index, self.vocabulary_index2word  = create_voabulary(self.config.word2vec_model_path)\n",
    "        self.config.vocab_size = len(self.vocabulary_word2index)+1\n",
    "        #这里通过实际的word2vec模型统计词典中词的数量，赋值到config中，然后加载CNN模型\n",
    "        self.model = CNN_K_MAXPOOL_DISEASE(self.config)\n",
    "        print(self.config.vocab_size)\n",
    "        self.word2vecModel = Word2Vec.load(self.config.word2vec_model_path)\n",
    "    \n",
    "        self.save_dir = 'checkpoints/textrnn'\n",
    "        self.save_path = os.path.join(self.save_dir, 'best_validation')  # 最佳验证结果保存路径\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()\n",
    "        #if not os.path.exists(save_dir):\n",
    "        #    os.makedirs(save_dir)\n",
    "        self.saver.restore(sess=self.session, save_path=self.save_path)  # 读取保存的模型\n",
    "        \n",
    "    def get_time_dif(self,start_time):\n",
    "        \"\"\"获取已使用时间\"\"\"\n",
    "        end_time = time.time()\n",
    "        time_dif = end_time - start_time\n",
    "        return timedelta(seconds=int(round(time_dif)))\n",
    "\n",
    "\n",
    "    def feed_data(self,x_batch, y_batch, keep_prob):\n",
    "        feed_dict = {\n",
    "            self.model.input_x: x_batch,\n",
    "            self.model.input_y: y_batch,\n",
    "            self.model.dropout_keep_prob: keep_prob\n",
    "        }\n",
    "        return feed_dict\n",
    "\n",
    "\n",
    "    def evaluate(self,sess, x, y):\n",
    "        \"\"\"评估在某一数据上的准确率和损失\"\"\"\n",
    "        #batch_eval = batch_iter(x_, y_, config.batch_size)\n",
    "        batch_size = self.config.batch_size\n",
    "        total_loss = 0.0\n",
    "        total_acc = 0.0\n",
    "        eval_out = []\n",
    "        data_len = len(x)\n",
    "        num_batch = int((data_len - 1) / batch_size) + 1\n",
    "\n",
    "        indices = np.random.permutation(np.arange(data_len))\n",
    "        print(\"data_len=\", data_len, \" num_batch=\", num_batch)\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        x_shuffle = x[indices]\n",
    "        y_shuffle = y[indices]\n",
    "\n",
    "        for i in range(num_batch):\n",
    "            start_id = i * batch_size\n",
    "            end_id = min((i + 1) * batch_size, data_len)\n",
    "            x_batch, y_batch =  x_shuffle[start_id:end_id], y_shuffle[start_id:end_id]\n",
    "\n",
    "            batch_len = len(x_batch)\n",
    "            feed_dict = self.feed_data(x_batch, y_batch, 1.0)\n",
    "            loss, acc, y_pred_cls = sess.run([self.model.loss, self.model.acc, self.model.y_pred_cls], feed_dict=feed_dict)\n",
    "            total_loss += loss * batch_len\n",
    "            total_acc += acc * batch_len\n",
    "            eval_out = np.concatenate([eval_out, y_pred_cls])\n",
    "\n",
    "        return total_loss / data_len, total_acc / data_len, eval_out, y_shuffle\n",
    "    def test(self, x_val, y_val):\n",
    "\n",
    "        start_time = time.time()\n",
    "        print('Testing...')\n",
    "        total_loss, total_acc, eval_out, y_real = self.evaluate(self.session, x_val, y_val)\n",
    "        print(\"total_loss=\", total_loss, \" total_acc=\", total_acc)\n",
    "        print(metrics.classification_report(y_real,eval_out))\n",
    "\n",
    "        cm = metrics.confusion_matrix(y_real, eval_out)\n",
    "        print(\"cm====\\n\", cm)  \n",
    "    def predictBatch(self, test_data_path, test_label_path):\n",
    "        x_val, y_val = loadTrainOrTest_data_oneLabel(test_data_path, test_label_path, self.vocabulary_word2index)\n",
    "        x_val = pad_sequences(x_val, self.config.sentence_length)  # padding to max length   \\\n",
    "        self.test(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight shape: [7, 100, 1, 6]\n",
      "weight shape: [1200, 100]\n",
      "weight shape: [100, 14]\n",
      "input shape0= (?, 50)\n",
      "sent_embed shape= Tensor(\"inference/embedding_lookup:0\", shape=(?, 50, 100), dtype=float32)\n",
      "input shape: (?, 50, 100, 1)\n",
      "input_unstack shape: 100\n",
      "conv1-con shape= (?, 50, 100, 6)\n",
      "conv1-kemax-pool shape= (?, 50, 100, 6)\n",
      "trained shape= (?, 1200)\n",
      "out shape= (?, 14)\n",
      "232015\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-10c880c2c531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCnnKMaxPoolModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-4e750692be3a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#if not os.path.exists(save_dir):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#    os.makedirs(save_dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 读取保存的模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_time_dif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_path' is not defined"
     ]
    }
   ],
   "source": [
    "model = CnnKMaxPoolModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#输入测试文件地址\n",
    "test_data_path = \"../cnnDatasets/testAdmin.feature\"\n",
    "test_label_path = \"../cnnDatasets/testAdmin.label\"\n",
    "model.predictBatch(test_data_path, test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
